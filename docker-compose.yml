version: "3.9"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT:-2181}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME:-2000}
    ports:
      - "2181:2181"
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.3
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    restart: unless-stopped

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-ics_threat_detection}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  neo4j:
    image: neo4j:5.14
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-neo4j_password}
      - NEO4J_PLUGINS=["apoc"]
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
    restart: unless-stopped

  fastapi-backend:
    build:
      context: .
      dockerfile: services/backend/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - NEO4J_URI=${NEO4J_URI:-bolt://neo4j:7687}
      - NEO4J_USER=${NEO4J_USER:-neo4j}
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - CORS_ORIGINS=${CORS_ORIGINS}
      - DEMO_MODE=${DEMO_MODE:-true}
    depends_on:
      - kafka
      - postgres
      - redis
      - neo4j
    ports:
      - "8000:8000"
    restart: unless-stopped

  dashboard:
    build:
      context: .
      dockerfile: dashboard/Dockerfile
    environment:
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://fastapi-backend:8000}
    depends_on:
      - fastapi-backend
    ports:
      - "3000:3000"
    restart: unless-stopped

  flower-server:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "run_server.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    restart: unless-stopped

  fl-client-0:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "run_client.py", "--client-id", "0", "--model-type", "lstm_autoencoder", "--server-address", "flower-server:8080"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - flower-server
    restart: unless-stopped

  fl-client-1:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "run_client.py", "--client-id", "1", "--model-type", "lstm_autoencoder", "--server-address", "flower-server:8080"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - flower-server
    restart: unless-stopped

  fl-client-2:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "run_client.py", "--client-id", "2", "--model-type", "isolation_forest", "--server-address", "flower-server:8080"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - flower-server
    restart: unless-stopped

  network-simulator:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/network_simulator/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - kafka
    restart: unless-stopped

  anomaly-lstm:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/anomaly_lstm/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - network-simulator
    restart: unless-stopped

  anomaly-iforest:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/anomaly_iforest/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - network-simulator
    restart: unless-stopped

  anomaly-physics:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/anomaly_physics/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - network-simulator
    restart: unless-stopped

  threat-classifier:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/threat_classifier/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - anomaly-lstm
      - anomaly-iforest
      - anomaly-physics
    restart: unless-stopped

  severity-predictor:
    build:
      context: .
      dockerfile: docker/python-service.Dockerfile
    command: ["python", "services/severity_predictor/main.py"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - threat-classifier
    restart: unless-stopped

volumes:
  pgdata:
  redis_data:
  neo4j_data:
